
\section{Other topics}
\label{section:more}

\subsection{Null hypotheses in play}

\subsubsection{null1 model}

\subsubsection{biased composition model}

\subsubsection{null2 model}


\subsection{Profile scoring algorithms and implementations}

\subsubsection{MSV filter}

\subsubsection{Viterbi filter}

\subsubsection{Forward filter/parser}

\subsubsection{Backward parser}





\subsection{The steps in the target processing pipeline}

One comparison: one sequence to one HMM.

\begin{description}

\item[\textbf{Null1 model score.}]  

  The ``null1 model'' is a probabilistic model for the null hypothesis
  that the target sequence is not homologous to the query profile. The
  null model is a one-state HMM configured to generate ``random''
  sequences of the same mean length $L$ as the target sequence, with
  each residue drawn from a background frequency distribution (a
  standard i.i.d. model: residues are treated as independent and
  identically distributed). Currently, this background frequency
  distribution is hardcoded as the mean residue frequencies in
  Swissprot 50.8 (October 2006).

\item[\textbf{MSV Filter.}] 

 The sequence is aligned to the profile using a specialized model that
 allows multiple high-scoring local ungapped segments to match.  The
 optimal alignment score (Viterbi score) is calculated under this
 multisegment model, hence the term MSV, for ``multi-segment
 Viterbi''. This is HMMER's main speed heuristic.

 The MSV score is comparable to BLAST's sum score (optimal sum of
 ungapped alignment segments). HMMER calculates this score directly
 (in vectorized dynamic programming) without additional heuristics
 (such as BLAST's word hit and hit extension stages). Also, the MSV
 score is a true log-odds likelihood ratio, so it obeys conjectures
 about the expected score distribution \citep{Eddy08} that allow
 immediate and accurate calculation of the statistical significance
 (P-value) of the score.

 By default, comparisons with a P-value of $\leq$ 0.02 pass this
 filter, meaning that about $2\%$ of the comparisons pass. You can use
 the \ccode{--F1 <x>} option to change this threshold. For example,
 \ccode{--F1 <0.05>} would pass 5\% of the comparisons, making a
 search more sensitive but slower. Setting the threshold to $>1.0$
 (\ccode{--F1 99} for example) assures that all comparisons will
 pass. Shutting off the MSV filter may be worthwhile if you want to
 make sure you don't miss comparisons that have a lot of scattered
 insertions and deletions. Alternatively, the \ccode{--max} option
 causes the MSV filter step (and all other filter steps) to be
 bypassed.

 The MSV bit score is calculated as a log-odds score using the null1
 model for comparison. No correction for a biased composition or
 repetitive sequence is done at this stage. For comparisons involving
 biased sequences and/or profiles, more than 2\% of comparisons will
 pass the MSV filter. At the end of search output, there is a line
 like:

\begin{sreoutput}
 Passed MSV filter:                    107917  (0.020272); expected 106468.8 (0.02)
\end{sreoutput}

 which tells you how many and what fraction of comparisons passed the
 MSV filter, versus how many (and what fraction) were expected. 

\item[\textbf{Biased composition filter.}]
 Unfortunately some searches involving biased sequence/profile
 comparisons allow so many comparisons through the MSV filter that
 HMMER's speed performance is severely degraded. Although the final
 scores and E-values at the end of the pipeline will be calculated
 taking into account a ``null2'' model of biased composition and
 simple repetition, the null2 model is dependent on a full alignment
 ensemble calculation via the Forward/Backward algorithm, making it
 computationally complex, so it won't get calculated until the very
 end. The treatment of biased composition comparisons is probably the
 most serious problem remaining in HMMER3, and it will require more
 research. As a stopgap solution to rescuing most of the speed
 degradation while not sacrificing too much sensitivity, an \emph{ad
   hoc} biased composition filtering step is applied to remove highly
 biased comparisons.

 On the fly, a two-state HMM is constructed. One state emits residues
 from the background frequency distribution (same as the null1 model),
 and the other state emits residues from the mean residue composition
 of the profile (i.e. the expected composition of sequences generated
 by the core model, including match and insert states
 [\ccode{p7\_hmm.c:p7\_hmm\_SetComposition()}]). Thus if the profile
 is highly biased (cysteine-rich, for example; or highly hydrophobic
 with many transmembrane segments), this composition bias will be
 captured by this second state. This model's transitions are
 arbitrarily set such that state 1 emits an expected length of 400 at
 a time, and state 2 emits an expected length of M/8 at a time (for a
 profile of length M). An overall target sequence length distribution
 is set to a mean of $L$, identical to the null1 model. 

 The sequence is then rescored using this ``bias filter model'' in
 place of the null1 model, using the HMM Forward algorithm. (This
 replaces the null1 model score at all subsequent filter steps in the
 pipeline, until a final Forward score is calculated.) A new MSV bit
 score is obtained.

 If the P-value of this still satisfies the MSV thresholds, the
 sequence passes the biased composition filter. 

 The \ccode{--F1 <x>} option controls the P-value threshold for
 passing the MSV filter score, both before (with the simple null1
 model) and after the bias composition filter is applied.

 The \ccode{--max} option bypasses all filters in the pipeline,
 including the bias filter.

 The \ccode{--nobias} option turns off (bypasses) the biased
 composition filter.  The simple null1 model is used as a null
 hypothesis for MSV and in subsequent filter steps. The biased
 composition filter step compromises a small amount of sensitivity,
 and though it is good to have it on by default, you may want to shut
 it off if you know you will have no problem with biased composition
 hits.

 At the end of a search output, you will see a line like:

\begin{sreoutput}
 Passed bias filter:                   105665  (0.019849); expected 106468.8 (0.02)
\end{sreoutput}

 which tells you how many and what fraction of comparisons passed the
 biased composition filter, versus how many were expected. (If the
 filter was turned off, all comparisons pass.)

\item[\textbf{Viterbi filter.}]
 The sequence is now aligned to the profile using a fast Viterbi
 (optimal alignment) algorithm. 

 This Viterbi implementation is specialized for speed in several
 respects. It is implemented in 16-way parallel SIMD vector
 instructions, using reduced precision scores that have been scaled to
 8-bit integers (range 0..255). Reduced precision introduces a score
 jitter of about $\pm 1$ bit. Only one row of the dynamic programming
 matrix is stored, so the routine only recovers a score, not an
 optimal alignment. The representation has limited range; local
 alignment scores do not underflow, but high scoring comparisons will
 overflow and return infinity when they exceed about 20 bits; all
 score overflows automatically pass the filter.

 The Viterbi filter bit score is then computed using the appropriate
 null model log likelihood (the biased composition filter model score,
 or if the biased filter is off, the null1 model score).

 
 
 
 







 


 
 


  

\item[\textbf{Viterbi filter.}]

\item[\textbf{Forward score.}]

\item[\textbf{Backward score.}]

\item[\textbf{Domain definition.}]

\item[\textbf{Null2 model score applied.}]

\item[\textbf{Storage of significant hits.}]
\end{description}



\begin{description}
\item[\textbf{Posterior decoding.}]

\item[\textbf{Region identification.}]

\item[\textbf{Test for multidomain regions.}]

\item[\textbf{Resolve multidomain regions by clustering of alignment ensemble.}]

\item[\textbf{Domain envelope definition.}]

\item[\textbf{Rescore each envelope.}]
\end{description}


\begin{description}



\subsection{Tabular output}

\subsubsection{Target hits table}

The sequence target hits table has \textbf{16 whitespace-delimited
  fields} followed by a free text target sequence description, as
follows:

\begin{description}
\item[\emprog{(1) target:}]

\item[\emprog{(2) query:}] 

\item[\emprog{(3) E-value (full sequence):}] 

\item[\emprog{(4) score (full sequence):}] 

\item[\emprog{(5) Bias (full sequence):}] 

\item[\emprog{(6) E-value (best 1 domain):}] 

\item[\emprog{(7) score (best 1 domain):}] 

\item[\emprog{(8) bias (best 1 domain):}] 

\item[\emprog{(9) exp:}] Expected number of domains.

\item[\emprog{(10) reg:}] Number of regions defined.

\item[\emprog{(11) clu:}]  
  Number of regions analyzed by stochastic traceback and clustering.

\item[\emprog{(12) ov:}] 
  Number of overlaps.

\item[\emprog{(13) env:}] 
  Number of envelopes defined.

\item[\emprog{(14) dom:}] 
  Number of domains defined.

\item[\emprog{(15) rep:}] 
  Number of domains satisfying reporting thresholds.

\item[\emprog{(16) inc:}] 
  Number of domains satisfying inclusion thresholds.

\item[\emprog{(17) description of target:}] 
\end{description}








\subsubsection{Domain hits table}

The domain table has \textbf{20 whitespace-delimited fields} followed
by a free text target sequence description, as follows:

\begin{description}
\item[\emprog{(1) target:}]

\item[\emprog{(2) tlen:}]

\item[\emprog{(3) query:}]

\item[\emprog{(4) qlen:}]

\item[\emprog{(5) E-value:}]

\item[\emprog{(6) score:}]

\item[\emprog{(7) bias:}]

\item[\emprog{(8) \#:}]

\item[\emprog{(9) of:}]

\item[\emprog{(10) c-Evalue:}]

\item[\emprog{(11) i-Evalue:}]

\item[\emprog{(12) score:}]

\item[\emprog{(13) bias:}]

\item[\emprog{(14) from (hmm coord):}]

\item[\emprog{(15) to (hmm coord):}]

\item[\emprog{(16) from (ali coord):}]

\item[\emprog{(17) to (ali coord):}]

\item[\emprog{(18) from (env coord):}]

\item[\emprog{(19) to (env coord):}]

\item[\emprog{(20) acc:}]

\item[\emprog{(21) description of target:}]
\end{description}
